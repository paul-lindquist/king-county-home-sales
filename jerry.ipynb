{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "sns.set_theme(palette='magma_r')\n",
    "\n",
    "pd.set_option('display.max_rows', 100) # Allows Jupyter Notebook to expand how much data is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().apply(lambda s: s.apply(lambda x: format(x, 'f')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15,10))\n",
    "axs[0, 0].scatter(df.sqft_living, df.price)\n",
    "axs[0, 0].set_title('sqft_living')\n",
    "axs[0, 1].scatter(df.sqft_above, df.price)\n",
    "axs[0, 1].set_title('sqft_above')\n",
    "axs[1, 0].scatter(df.sqft_living15, df.price)\n",
    "axs[1, 0].set_title('sqft_living15')\n",
    "axs[1, 1].scatter(df.bathrooms, df.price)\n",
    "axs[1, 1].set_title('bathrooms')\n",
    "axs[2, 0].scatter(df.bedrooms, df.price)\n",
    "axs[2, 0].set_title('bedrooms')\n",
    "axs[2, 1].scatter(df.lat, df.price)\n",
    "axs[2, 1].set_title('lat')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_corr = df.corr()['price'].map(abs).sort_values(ascending=False)\n",
    "price_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),center=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_dupes(series):\n",
    "    series_vcs = pd.Series(series.value_counts())\n",
    "    series_dupes = [series_vcs.index[index] for index in range(len(series_vcs)) if series_vcs.values[index] > 1]\n",
    "    print(\"Amount of unique duplicates: \" + str(len(series_dupes)))\n",
    "    print(\"Total amount of duplicates: \" + str(series_vcs.values[0:len(series_dupes)].sum()))\n",
    "    \n",
    "    return series_vcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "determine_dupes(df.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['id'], keep='last')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['bedrooms']==33].index, inplace=True)\n",
    "df.drop(df.loc[df['bedrooms']==11].index, inplace=True)\n",
    "df.drop(df.loc[df['bedrooms']==10].index, inplace=True)\n",
    "df.drop(df.loc[df['bedrooms']==9].index, inplace=True)\n",
    "\n",
    "df.sort_values('bedrooms', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.yr_renovated = df.yr_renovated.fillna(0)\n",
    "df.yr_renovated = df.yr_renovated.astype('int64')\n",
    "\n",
    "df.view = df.view.fillna('NONE')\n",
    "\n",
    "df.waterfront = df.waterfront.fillna('NO')\n",
    "\n",
    "df.loc[df.sqft_basement == '?', 'sqft_basement'] = 0.0\n",
    "df.sqft_basement = df.sqft_basement.astype('float64').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.grade = pd.to_numeric(df.grade.map(lambda x: x.split()[0]))\n",
    "for index in df.grade.value_counts().sort_index().index:\n",
    "    df.grade.replace(index, index-2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing condition from string to numeric\n",
    "df['condition'].replace('Poor', 1, inplace=True)\n",
    "df['condition'].replace('Fair', 2, inplace=True)\n",
    "df['condition'].replace('Average', 3, inplace=True)\n",
    "df['condition'].replace('Good', 4, inplace=True)\n",
    "df['condition'].replace('Very Good', 5, inplace=True)\n",
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "df['waterfront'] = lb_make.fit_transform(df['waterfront'])\n",
    "df.waterfront.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['view'].replace('NONE', 0, inplace=True)\n",
    "df['view'].replace('FAIR', 2, inplace=True)\n",
    "df['view'].replace('AVERAGE', 3, inplace=True)\n",
    "df['view'].replace('GOOD', 4, inplace=True)\n",
    "df['view'].replace('EXCELLENT', 5, inplace=True)\n",
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_train, fit=stats.norm)\n",
    "fig = plt.figure()\n",
    "stats.probplot(y_train, plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of price is not normal. A transfromation may be needed to normalize the distribution of price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)\n",
    "\n",
    "sns.distplot(y_train_log, fit=stats.norm)\n",
    "fig = plt.figure()\n",
    "stats.probplot(y_train_log, plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log transformation normalized the distribution well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "heatmap_data = pd.concat([y_train, X_train], axis=1)\n",
    "corr = heatmap_data.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 13))\n",
    "\n",
    "sns.heatmap(\n",
    "    \n",
    "    data=corr,\n",
    "    \n",
    "    mask=np.triu(np.ones_like(corr, dtype=bool)),\n",
    "    \n",
    "    ax=ax,\n",
    "    \n",
    "    annot=True,\n",
    "    \n",
    "    cbar_kws={\"label\": \"Correlation\", \"orientation\": \"horizontal\", \"pad\": .2, \"extend\": \"both\"}\n",
    ")\n",
    "\n",
    "# Customize the plot appearance\n",
    "ax.set_title(\"Heatmap of Correlation Between Attributes (Including Target)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the heat map, sqft_living is the hightest correlated feature to price. Other highly correlated features include bathroom, grade, sqft_above, sqft_living, and sqft_basement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X_train['sqft_living'], y_train, alpha=0.5)\n",
    "ax.set_xlabel('sqft_living')\n",
    "ax.set_ylabel(\"House Price\")\n",
    "ax.set_title(\"sqft_living vs. House Price\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = DummyRegressor(strategy='mean')\n",
    "baseline.fit(X_train,y_train_log)\n",
    "baseline.score(X_test,y_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run our first model using only the most correlated independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_model = LinearRegression()\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=3, test_size=0.25, random_state=0)\n",
    "\n",
    "first_scores = cross_validate(estimator=first_model,\n",
    "                                 X=X_train[['sqft_living']],\n",
    "                                 y=y_train_log, return_train_score=True,\n",
    "                                 cv=splitter)\n",
    "\n",
    "print('Train score: ', first_scores['train_score'].mean())\n",
    "print('Validation score: ', first_scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting relevant columns as features for our second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = X_train[['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "                             'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "                             'sqft_above', 'sqft_basement', 'sqft_living15',\n",
    "                             'sqft_lot15']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = LinearRegression()\n",
    "\n",
    "second_model_scores = cross_validate(\n",
    "    estimator=second_model,\n",
    "    X=select_features,\n",
    "    y=y_train_log,\n",
    "    return_train_score=True,\n",
    "    cv=splitter\n",
    ")\n",
    "\n",
    "print(\"Current Model\")\n",
    "print(\"Train score:     \", second_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", second_model_scores[\"test_score\"].mean())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "sm.OLS(y_train, sm.add_constant(select_features)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at p-values, remove sqft_above, floors, and sqft_lot.\n",
    "select_features = select_features.drop(['sqft_above','floors','sqft_lot'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_model = LinearRegression()\n",
    "\n",
    "third_model_scores = cross_validate(estimator=third_model,\n",
    "                                     X=select_features, y=y_train_log,\n",
    "                                     return_train_score=True, cv=splitter)\n",
    "print(\"Current Model\")\n",
    "print(\"Train score:     \", third_model_scores[\"train_score\"].mean())\n",
    "print(\"Validation score:\", third_model_scores[\"test_score\"].mean())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.OLS(y_train, sm.add_constant(select_features)).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "X_train_for_RFECV = StandardScaler().fit_transform(select_features)\n",
    "\n",
    "model_for_RFECV = LinearRegression()\n",
    "\n",
    "selector = RFECV(model_for_RFECV, cv=splitter)\n",
    "selector.fit(X_train_for_RFECV, y_train_log)\n",
    "\n",
    "print(\"Was the column selected?\")\n",
    "for index, col in enumerate(select_features.columns):\n",
    "    print(f\"{col}: {selector.support_[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n",
    "                  'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "                  'sqft_living15', 'sqft_lot15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train[select_features]\n",
    "X_test_final = X_test[select_features]\n",
    "\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_final, y_train)\n",
    "\n",
    "final_model.score(X_test_final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Assumptions of Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_model.predict(X_test_final)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "perfect_line = np.arange(y_test.min(), y_test.max())\n",
    "ax.plot(perfect_line, color=\"g\", label=\"Perfect Fit\")\n",
    "ax.scatter(y_test, preds, alpha=0.5)\n",
    "ax.set_xlabel(\"Actual Price\")\n",
    "ax.set_ylabel(\"Predicted Price\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter shows a linear relationship of the features vs the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "residuals = (y_test - preds)\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the qqplot we can see that the residuals are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = [variance_inflation_factor(X_train_final.values, i) for i in range(X_train_final.shape[1])]\n",
    "pd.Series(vif, index=X_train_final.columns, name=\"Variance Inflation Factor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VIF values for all the features minus waterfront, view, sqft_lot15, and sqft_lot are high. This indicates there is is strong multicollinearity among the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homoskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(preds, residuals, alpha=0.5)\n",
    "ax.plot(preds, [0 for i in range(len(X_test))])\n",
    "ax.set_xlabel(\"Predicted Value\")\n",
    "ax.set_ylabel(\"Actual - Predicted Value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clear funnel shaped pattern is shown for the scatter of residuals vs predicted value which indicates that the Homoskedasticity assumption is not fulfilled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
